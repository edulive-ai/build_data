import os
import cv2
import json
import fitz  # PyMuPDF
import numpy as np
from pathlib import Path
from datetime import datetime
from doclayout_yolo import YOLOv10
from huggingface_hub import hf_hub_download

class YOLOBatchProcessor:
    def __init__(self, input_dir, output_dir):
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        
        # T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c ƒë·∫ßu ra
        self.all_detections_dir = self.output_dir / "books_detections/30-de-thi"
        # self.valid_detections_dir = self.output_dir / "valid_detections"
        self.cropped_dir = self.output_dir / "books_cropped/30-de-thi"
        
        self.all_detections_dir.mkdir(parents=True, exist_ok=True)
        # self.valid_detections_dir.mkdir(parents=True, exist_ok=True)
        self.cropped_dir.mkdir(parents=True, exist_ok=True)
        
        # === Kh√¥ng s·ª≠ d·ª•ng ƒëi·ªÅu ki·ªán l·ªçc - L·∫•y t·∫•t c·∫£ bbox ===
        # ƒê√£ b·ªè t·∫•t c·∫£ ƒëi·ªÅu ki·ªán l·ªçc theo y√™u c·∫ßu
        
        # ƒê·ªãnh d·∫°ng file ƒë∆∞·ª£c h·ªó tr·ª£
        self.SUPPORTED_FORMATS = {'.png', '.jpg', '.jpeg', '.pdf', '.tiff', '.tif', '.bmp'}
        
        # Th·ªëng k√™ t·ªïng quan
        self.total_images = 0
        self.processed_images = 0
        self.failed_images = 0
        self.total_bboxes = 0
        self.total_valid_bboxes = 0
        
        print(f"üîß C·∫•u h√¨nh x·ª≠ l√Ω:")
        print(f"   - Th∆∞ m·ª•c ƒë·∫ßu v√†o: {self.input_dir}")
        print(f"   - Th∆∞ m·ª•c ƒë·∫ßu ra: {self.output_dir}")
        print(f"   - Th∆∞ m·ª•c t·∫•t c·∫£ detections: {self.all_detections_dir}")
        # print(f"   - Th∆∞ m·ª•c valid detections: {self.valid_detections_dir}")
        print(f"   - Th∆∞ m·ª•c cropped: {self.cropped_dir}")
        print(f"   - Ch·∫ø ƒë·ªô: L·∫•y T·∫§T C·∫¢ bbox (kh√¥ng l·ªçc)")
        
    def load_model(self):
        """Load YOLO model"""
        try:
            print("ü§ñ ƒêang t·∫£i model YOLO...")
            filepath = hf_hub_download(
                repo_id="juliozhao/DocLayout-YOLO-DocStructBench",
                filename="doclayout_yolo_docstructbench_imgsz1024.pt"
            )
            self.model = YOLOv10(filepath)
            print("‚úÖ Model ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
            return True
        except Exception as e:
            print(f"‚ùå L·ªói khi t·∫£i model: {e}")
            return False
    
    def get_image_files(self):
        """L·∫•y danh s√°ch file ·∫£nh trong th∆∞ m·ª•c"""
        image_files = []
        for file_path in self.input_dir.rglob("*"):
            if file_path.is_file() and file_path.suffix.lower() in self.SUPPORTED_FORMATS:
                image_files.append(file_path)
        return sorted(image_files)
    
    def load_image_with_fitz(self, image_path):
        """
        Load ·∫£nh b·∫±ng fitz (gi·ªëng h·ªát code ƒë∆°n) ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng cao
        """
        try:
            # === D√πng fitz ƒë·ªÉ ƒë·ªçc ·∫£nh ch·∫•t l∆∞·ª£ng cao (gi·ªëng code ƒë∆°n) ===
            doc = fitz.open(str(image_path))
            pix = doc[0].get_pixmap(dpi=300)  # ·∫£nh g·ªëc c√≥ th·ªÉ r·∫•t l·ªõn
            fitz_img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)
            if pix.n == 4:  # n·∫øu c√≥ alpha
                fitz_img = cv2.cvtColor(fitz_img, cv2.COLOR_RGBA2RGB)
            
            fitz_h, fitz_w = fitz_img.shape[:2]
            doc.close()
            
            # === D√πng OpenCV ƒë·ªÉ l·∫•y k√≠ch th∆∞·ªõc ·∫£nh YOLO resize (gi·ªëng code ƒë∆°n) ===
            yolo_input = cv2.imread(str(image_path))
            if yolo_input is None:
                # Fallback: t·∫°o yolo_input t·ª´ fitz_img
                yolo_input = cv2.cvtColor(fitz_img, cv2.COLOR_RGB2BGR)
            
            yolo_h, yolo_w = yolo_input.shape[:2]
            
            return {
                "fitz_img": fitz_img,
                "yolo_input": yolo_input,
                "fitz_size": (fitz_w, fitz_h),
                "yolo_size": (yolo_w, yolo_h),
                "success": True
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def process_single_image(self, image_path, image_index):
        """X·ª≠ l√Ω m·ªôt ·∫£nh (logic gi·ªëng h·ªát code ƒë∆°n)"""
        try:
            image_name = f"image_{image_index:04d}"
            print(f"\nüì∏ ƒêang x·ª≠ l√Ω: {image_path.name} -> {image_name}")
            
            # T·∫°o th∆∞ m·ª•c con cho ·∫£nh crop
            crop_subdir = self.cropped_dir / image_name
            crop_subdir.mkdir(exist_ok=True)
            
            # === Load ·∫£nh b·∫±ng fitz (gi·ªëng code ƒë∆°n) ===
            image_data = self.load_image_with_fitz(image_path)
            if not image_data["success"]:
                raise ValueError(f"Kh√¥ng th·ªÉ load ·∫£nh: {image_data['error']}")
            
            fitz_img = image_data["fitz_img"]
            yolo_input = image_data["yolo_input"]
            fitz_w, fitz_h = image_data["fitz_size"]
            yolo_w, yolo_h = image_data["yolo_size"]
            
            # === T√≠nh h·ªá s·ªë scale (gi·ªëng code ƒë∆°n) ===
            scale_x = fitz_w / yolo_w
            scale_y = fitz_h / yolo_h
            
            print(f"   üìè K√≠ch th∆∞·ªõc:")
            print(f"       - YOLO input: {yolo_w}x{yolo_h}")
            print(f"       - ·∫¢nh g·ªëc: {fitz_w}x{fitz_h}")
            print(f"       - Scale: x={scale_x:.3f}, y={scale_y:.3f}")
            
            # === D·ª± ƒëo√°n YOLO ===
            det_res = self.model.predict(str(image_path), imgsz=1024, conf=0.2, device="cuda")
            
            if not det_res[0].boxes:
                print(f"‚ö†Ô∏è  Kh√¥ng ph√°t hi·ªán bbox n√†o trong {image_path.name}")
                return self._create_empty_result(image_path, image_name, fitz_w, fitz_h, yolo_w, yolo_h, scale_x, scale_y)
            
            # === X·ª≠ l√Ω T·∫§T C·∫¢ bbox (kh√¥ng l·ªçc) ===
            all_bboxes = []
            
            for i, result in enumerate(det_res[0].boxes):
                bbox_result = self._process_bbox(
                    result, i, scale_x, scale_y, fitz_img, 
                    crop_subdir, i, image_name
                )
                all_bboxes.append(bbox_result["bbox_info"])
            
            # === T·∫°o ·∫£nh annotated ===
            # 1. ·∫¢nh v·ªõi t·∫•t c·∫£ bbox -> all_detections
            annotated_all = det_res[0].plot(pil=True, line_width=5, font_size=20)
            annotated_all_path = self.all_detections_dir / f"{image_name}_all_bboxes.jpg"
            cv2.imwrite(str(annotated_all_path), cv2.cvtColor(np.array(annotated_all), cv2.COLOR_RGB2BGR))
            
            # 2. ·∫¢nh v·ªõi bbox -> valid_detections (gi·ªëng all v√¨ kh√¥ng l·ªçc)
            # annotated_path = self.valid_detections_dir / f"{image_name}_annotated.jpg"
            # cv2.imwrite(str(annotated_path), cv2.cvtColor(np.array(annotated_all), cv2.COLOR_RGB2BGR))
            
            # === Th·ªëng k√™ ·∫£nh ===
            total_boxes = len(det_res[0].boxes)
            result = {
                "image_info": {
                    "original_path": str(image_path),
                    "image_name": image_name,
                    "original_filename": image_path.name,
                    "image_size": [fitz_w, fitz_h],
                    "yolo_size": [yolo_w, yolo_h],
                    "scale": [scale_x, scale_y]
                },
                "statistics": {
                    "total_boxes": total_boxes,
                    "cropped_boxes": len(all_bboxes)
                },
                "all_bboxes": all_bboxes,
                "paths": {
                    "all_detections": str(annotated_all_path),
                    # "annotated": str(annotated_path),
                    "cropped_folder": str(crop_subdir)
                },
                "status": "success"
            }
            
            self.total_bboxes += total_boxes
            self.total_valid_bboxes += len(all_bboxes)
            
            print(f"   ‚úÖ Ho√†n th√†nh: ƒê√£ crop {len(all_bboxes)}/{total_boxes} bbox")
            return result
            
        except Exception as e:
            error_msg = f"L·ªói x·ª≠ l√Ω {image_path.name}: {str(e)}"
            print(f"   ‚ùå {error_msg}")
            self.failed_images += 1
            return {
                "image_info": {
                    "original_path": str(image_path),
                    "image_name": f"image_{image_index:04d}",
                    "original_filename": image_path.name,
                    "error": error_msg
                },
                "status": "failed"
            }
    
    def _process_bbox(self, result, bbox_index, scale_x, scale_y, fitz_img, crop_subdir, crop_count, image_name):
        """X·ª≠ l√Ω m·ªôt bbox - L·∫•y t·∫•t c·∫£ kh√¥ng l·ªçc"""
        x1, y1, x2, y2 = result.xyxy[0].tolist()
        
        # Scale v·ªÅ t·ªça ƒë·ªô ·∫£nh g·ªëc
        scaled_x1 = int(x1 * scale_x)
        scaled_y1 = int(y1 * scale_y)
        scaled_x2 = int(x2 * scale_x)
        scaled_y2 = int(y2 * scale_y)
        
        # T√≠nh k√≠ch th∆∞·ªõc
        width = scaled_x2 - scaled_x1
        height = scaled_y2 - scaled_y1
        area = width * height
        
        bbox_info = {
            "index": bbox_index,
            "class_id": int(result.cls[0]),
            "confidence": float(result.conf[0]),
            "bbox": [scaled_x1, scaled_y1, scaled_x2, scaled_y2],
            "width": width,
            "height": height,
            "area": area
        }
        
        # === Crop v√† l∆∞u T·∫§T C·∫¢ bbox ===
        cropped = fitz_img[scaled_y1:scaled_y2, scaled_x1:scaled_x2]
        
        # L√†m n√©t ·∫£nh b·∫±ng kernel sharpen
        sharpen_kernel = np.array([[0, -1, 0],
                                   [-1, 5, -1],
                                   [0, -1, 0]])
        sharpened = cv2.filter2D(cropped, -1, sharpen_kernel)
        
        # L∆∞u v·ªõi t√™n file
        crop_filename = f"crop_{crop_count:03d}_cls{int(result.cls[0])}.png"
        crop_path = crop_subdir / crop_filename
        
        # Chuy·ªÉn t·ª´ RGB sang BGR tr∆∞·ªõc khi l∆∞u (v√¨ cv2.imwrite expect BGR)
        cv2.imwrite(str(crop_path), cv2.cvtColor(sharpened, cv2.COLOR_RGB2BGR))
        
        bbox_info["crop_path"] = str(crop_path)
        bbox_info["crop_filename"] = crop_filename
        
        print(f"      ‚úÖ Bbox {bbox_index} -> crop_{crop_count}: [{scaled_x1}, {scaled_y1}, {scaled_x2}, {scaled_y2}] "
              f"(W:{width}, H:{height}, Area:{area:,}) -> {crop_filename}")
        
        return {
            "bbox_info": bbox_info
        }
    

    
    def _create_empty_result(self, image_path, image_name, fitz_w, fitz_h, yolo_w, yolo_h, scale_x, scale_y):
        """T·∫°o k·∫øt qu·∫£ r·ªóng cho ·∫£nh kh√¥ng c√≥ bbox"""
        return {
            "image_info": {
                "original_path": str(image_path),
                "image_name": image_name,
                "original_filename": image_path.name,
                "image_size": [fitz_w, fitz_h],
                "yolo_size": [yolo_w, yolo_h],
                "scale": [scale_x, scale_y]
            },
            "statistics": {
                "total_boxes": 0,
                "cropped_boxes": 0
            },
            "all_bboxes": [],
            "paths": {
                "all_detections": None,
                "annotated": None,
                "cropped_folder": None
            },
            "status": "no_detection"
        }
    
    def process_batch(self):
        """X·ª≠ l√Ω t·∫•t c·∫£ ·∫£nh trong th∆∞ m·ª•c"""
        # Load model
        if not self.load_model():
            return False
        
        # L·∫•y danh s√°ch file ·∫£nh
        image_files = self.get_image_files()
        self.total_images = len(image_files)
        
        if self.total_images == 0:
            print("‚ùå Kh√¥ng t√¨m th·∫•y file ·∫£nh n√†o trong th∆∞ m·ª•c!")
            return False
        
        print(f"\nüöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω {self.total_images} ·∫£nh...")
        
        # X·ª≠ l√Ω t·ª´ng ·∫£nh
        all_results = []
        
        for i, image_path in enumerate(image_files):
            result = self.process_single_image(image_path, i)
            all_results.append(result)
            
            if result["status"] == "success":
                self.processed_images += 1
        
        # === L∆∞u k·∫øt qu·∫£ t·ªïng h·ª£p ===
        self._save_batch_results(all_results)
        
        # === Th·ªëng k√™ cu·ªëi c√πng ===
        self._print_final_statistics()
        
        return True
    
    def _save_batch_results(self, all_results):
        """L∆∞u k·∫øt qu·∫£ t·ªïng h·ª£p trong th∆∞ m·ª•c g·ªëc output"""
        batch_result = {
                            "config": {
                "input_directory": str(self.input_dir),
                "output_directory": str(self.output_dir),
                "all_detections_directory": str(self.all_detections_dir),
                # "valid_detections_directory": str(self.valid_detections_dir),
                "cropped_directory": str(self.cropped_dir),
                "filtering": "disabled - take all bboxes",
                "supported_formats": list(self.SUPPORTED_FORMATS),
                "processing_time": datetime.now().isoformat()
            },
            "batch_statistics": {
                "total_images": self.total_images,
                "processed_images": self.processed_images,
                "failed_images": self.failed_images,
                "success_rate": self.processed_images/self.total_images*100 if self.total_images > 0 else 0,
                "total_bboxes": self.total_bboxes,
                "total_cropped_bboxes": self.total_valid_bboxes,
                "crop_rate": 100.0  # 100% v√¨ kh√¥ng l·ªçc
            },
            "results": all_results
        }
        
        # L∆∞u JSON t·ªïng h·ª£p trong th∆∞ m·ª•c g·ªëc output
        # batch_json_path = self.output_dir / "batch_results.json"
        # with open(batch_json_path, "w", encoding='utf-8') as f:
        #     json.dump(batch_result, f, ensure_ascii=False, indent=2)
        
        # print(f"\nüíæ ƒê√£ l∆∞u k·∫øt qu·∫£ t·ªïng h·ª£p: {batch_json_path}")
    
    def _print_final_statistics(self):
        """In th·ªëng k√™ cu·ªëi c√πng"""
        print(f"\n" + "="*60)
        print(f"üéØ HO√ÄN TH√ÄNH X·ª¨ L√ù BATCH")
        print(f"="*60)
        print(f"üìä Th·ªëng k√™ t·ªïng quan:")
        print(f"   - T·ªïng s·ªë ·∫£nh: {self.total_images}")
        print(f"   - ·∫¢nh x·ª≠ l√Ω th√†nh c√¥ng: {self.processed_images}")
        print(f"   - ·∫¢nh b·ªã l·ªói: {self.failed_images}")
        print(f"   - T·ª∑ l·ªá th√†nh c√¥ng: {self.processed_images/self.total_images*100:.1f}%")
        print(f"   - T·ªïng bbox ph√°t hi·ªán: {self.total_bboxes:,}")
        print(f"   - T·ªïng bbox ƒë√£ crop: {self.total_valid_bboxes:,}")
        print(f"   - T·ª∑ l·ªá crop: 100% (kh√¥ng l·ªçc)")
        
        print(f"\nüìÅ K·∫øt qu·∫£ ƒë·∫ßu ra:")
        print(f"   - ·∫¢nh t·∫•t c·∫£ detections: {self.all_detections_dir}")
        # print(f"   - ·∫¢nh valid detections: {self.valid_detections_dir}")
        print(f"   - ·∫¢nh crop: {self.cropped_dir}")
        print(f"   - JSON t·ªïng h·ª£p: {self.output_dir}/batch_results.json")


def main():
    # === C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n ===
    INPUT_DIR = "books_to_images/30-de-thi"  # Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n n√†y
    OUTPUT_DIR = "."  # Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n n√†y
    
    # T·∫°o processor v√† ch·∫°y
    processor = YOLOBatchProcessor(INPUT_DIR, OUTPUT_DIR)
    processor.process_batch()


if __name__ == "__main__":
    main()