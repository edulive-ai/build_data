import os
import cv2
import json
import fitz  # PyMuPDF
import numpy as np
from pathlib import Path
from datetime import datetime
from doclayout_yolo import YOLOv10
from huggingface_hub import hf_hub_download

class YOLOBatchProcessor:
    def __init__(self, input_dir, output_dir):
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        
        # Táº¡o cáº¥u trÃºc thÆ° má»¥c Ä‘áº§u ra
        self.all_detections_dir = self.output_dir / "books_detections/30-de-thi"
        # self.valid_detections_dir = self.output_dir / "valid_detections"
        self.cropped_dir = self.output_dir / "books_cropped/30-de-thi"
        
        self.all_detections_dir.mkdir(parents=True, exist_ok=True)
        # self.valid_detections_dir.mkdir(parents=True, exist_ok=True)
        self.cropped_dir.mkdir(parents=True, exist_ok=True)
        
        # === KhÃ´ng sá»­ dá»¥ng Ä‘iá»u kiá»‡n lá»c - Láº¥y táº¥t cáº£ bbox ===
        # ÄÃ£ bá» táº¥t cáº£ Ä‘iá»u kiá»‡n lá»c theo yÃªu cáº§u
        
        # Äá»‹nh dáº¡ng file Ä‘Æ°á»£c há»— trá»£
        self.SUPPORTED_FORMATS = {'.png', '.jpg', '.jpeg', '.pdf', '.tiff', '.tif', '.bmp'}
        
        # Thá»‘ng kÃª tá»•ng quan
        self.total_images = 0
        self.processed_images = 0
        self.failed_images = 0
        self.total_bboxes = 0
        self.total_valid_bboxes = 0
        
        print(f"ğŸ”§ Cáº¥u hÃ¬nh xá»­ lÃ½:")
        print(f"   - ThÆ° má»¥c Ä‘áº§u vÃ o: {self.input_dir}")
        print(f"   - ThÆ° má»¥c Ä‘áº§u ra: {self.output_dir}")
        print(f"   - ThÆ° má»¥c táº¥t cáº£ detections: {self.all_detections_dir}")
        # print(f"   - ThÆ° má»¥c valid detections: {self.valid_detections_dir}")
        print(f"   - ThÆ° má»¥c cropped: {self.cropped_dir}")
        print(f"   - Cháº¿ Ä‘á»™: Láº¥y Táº¤T Cáº¢ bbox (khÃ´ng lá»c)")
        
    def load_model(self):
        """Load YOLO model"""
        try:
            print("ğŸ¤– Äang táº£i model YOLO...")
            filepath = hf_hub_download(
                repo_id="juliozhao/DocLayout-YOLO-DocStructBench",
                filename="doclayout_yolo_docstructbench_imgsz1024.pt"
            )
            self.model = YOLOv10(filepath)
            print("âœ… Model Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!")
            return True
        except Exception as e:
            print(f"âŒ Lá»—i khi táº£i model: {e}")
            return False
    
    def get_image_files(self):
        """Láº¥y danh sÃ¡ch file áº£nh trong thÆ° má»¥c"""
        image_files = []
        for file_path in self.input_dir.rglob("*"):
            if file_path.is_file() and file_path.suffix.lower() in self.SUPPORTED_FORMATS:
                image_files.append(file_path)
        return sorted(image_files)
    
    def load_image_with_fitz(self, image_path):
        """
        Load áº£nh báº±ng fitz (giá»‘ng há»‡t code Ä‘Æ¡n) Ä‘á»ƒ Ä‘áº£m báº£o cháº¥t lÆ°á»£ng cao
        """
        try:
            # === DÃ¹ng fitz Ä‘á»ƒ Ä‘á»c áº£nh cháº¥t lÆ°á»£ng cao (giá»‘ng code Ä‘Æ¡n) ===
            doc = fitz.open(str(image_path))
            pix = doc[0].get_pixmap(dpi=300)  # áº£nh gá»‘c cÃ³ thá»ƒ ráº¥t lá»›n
            fitz_img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)
            if pix.n == 4:  # náº¿u cÃ³ alpha
                fitz_img = cv2.cvtColor(fitz_img, cv2.COLOR_RGBA2RGB)
            
            fitz_h, fitz_w = fitz_img.shape[:2]
            doc.close()
            
            # === DÃ¹ng OpenCV Ä‘á»ƒ láº¥y kÃ­ch thÆ°á»›c áº£nh YOLO resize (giá»‘ng code Ä‘Æ¡n) ===
            yolo_input = cv2.imread(str(image_path))
            if yolo_input is None:
                # Fallback: táº¡o yolo_input tá»« fitz_img
                yolo_input = cv2.cvtColor(fitz_img, cv2.COLOR_RGB2BGR)
            
            yolo_h, yolo_w = yolo_input.shape[:2]
            
            return {
                "fitz_img": fitz_img,
                "yolo_input": yolo_input,
                "fitz_size": (fitz_w, fitz_h),
                "yolo_size": (yolo_w, yolo_h),
                "success": True
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def process_single_image(self, image_path, image_index):
        """Xá»­ lÃ½ má»™t áº£nh (logic giá»‘ng há»‡t code Ä‘Æ¡n)"""
        try:
            image_name = f"image_{image_index:04d}"
            print(f"\nğŸ“¸ Äang xá»­ lÃ½: {image_path.name} -> {image_name}")
            
            # Táº¡o thÆ° má»¥c con cho áº£nh crop
            crop_subdir = self.cropped_dir / image_name
            crop_subdir.mkdir(exist_ok=True)
            
            # === Load áº£nh báº±ng fitz (giá»‘ng code Ä‘Æ¡n) ===
            image_data = self.load_image_with_fitz(image_path)
            if not image_data["success"]:
                raise ValueError(f"KhÃ´ng thá»ƒ load áº£nh: {image_data['error']}")
            
            fitz_img = image_data["fitz_img"]
            yolo_input = image_data["yolo_input"]
            fitz_w, fitz_h = image_data["fitz_size"]
            yolo_w, yolo_h = image_data["yolo_size"]
            
            # === TÃ­nh há»‡ sá»‘ scale (giá»‘ng code Ä‘Æ¡n) ===
            scale_x = fitz_w / yolo_w
            scale_y = fitz_h / yolo_h
            
            print(f"   ğŸ“ KÃ­ch thÆ°á»›c:")
            print(f"       - YOLO input: {yolo_w}x{yolo_h}")
            print(f"       - áº¢nh gá»‘c: {fitz_w}x{fitz_h}")
            print(f"       - Scale: x={scale_x:.3f}, y={scale_y:.3f}")
            
            # === Dá»± Ä‘oÃ¡n YOLO ===
            det_res = self.model.predict(str(image_path), imgsz=1024, conf=0.2, device="cuda")
            
            if not det_res[0].boxes:
                print(f"âš ï¸  KhÃ´ng phÃ¡t hiá»‡n bbox nÃ o trong {image_path.name}")
                return self._create_empty_result(image_path, image_name, fitz_w, fitz_h, yolo_w, yolo_h, scale_x, scale_y)
            
            # === Xá»­ lÃ½ Táº¤T Cáº¢ bbox (khÃ´ng lá»c) ===
            all_bboxes = []
            
            for i, result in enumerate(det_res[0].boxes):
                bbox_result = self._process_bbox(
                    result, i, scale_x, scale_y, fitz_img, 
                    crop_subdir, i, image_name
                )
                all_bboxes.append(bbox_result["bbox_info"])
            
            # === Táº¡o áº£nh annotated ===
            # 1. áº¢nh vá»›i táº¥t cáº£ bbox -> all_detections
            annotated_all = det_res[0].plot(pil=True, line_width=5, font_size=20)
            annotated_all_path = self.all_detections_dir / f"{image_name}_all_bboxes.jpg"
            cv2.imwrite(str(annotated_all_path), cv2.cvtColor(np.array(annotated_all), cv2.COLOR_RGB2BGR))
            
            # 2. áº¢nh vá»›i bbox -> valid_detections (giá»‘ng all vÃ¬ khÃ´ng lá»c)
            # annotated_path = self.valid_detections_dir / f"{image_name}_annotated.jpg"
            # cv2.imwrite(str(annotated_path), cv2.cvtColor(np.array(annotated_all), cv2.COLOR_RGB2BGR))
            
            # === Thá»‘ng kÃª áº£nh ===
            total_boxes = len(det_res[0].boxes)
            result = {
                "image_info": {
                    "original_path": str(image_path),
                    "image_name": image_name,
                    "original_filename": image_path.name,
                    "image_size": [fitz_w, fitz_h],
                    "yolo_size": [yolo_w, yolo_h],
                    "scale": [scale_x, scale_y]
                },
                "statistics": {
                    "total_boxes": total_boxes,
                    "cropped_boxes": len(all_bboxes)
                },
                "all_bboxes": all_bboxes,
                "paths": {
                    "all_detections": str(annotated_all_path),
                    # "annotated": str(annotated_path),
                    "cropped_folder": str(crop_subdir)
                },
                "status": "success"
            }
            
            self.total_bboxes += total_boxes
            self.total_valid_bboxes += len(all_bboxes)
            
            print(f"   âœ… HoÃ n thÃ nh: ÄÃ£ crop {len(all_bboxes)}/{total_boxes} bbox")
            return result
            
        except Exception as e:
            error_msg = f"Lá»—i xá»­ lÃ½ {image_path.name}: {str(e)}"
            print(f"   âŒ {error_msg}")
            self.failed_images += 1
            return {
                "image_info": {
                    "original_path": str(image_path),
                    "image_name": f"image_{image_index:04d}",
                    "original_filename": image_path.name,
                    "error": error_msg
                },
                "status": "failed"
            }
    
    def _process_bbox(self, result, bbox_index, scale_x, scale_y, fitz_img, crop_subdir, crop_count, image_name):
        """Xá»­ lÃ½ má»™t bbox - Láº¥y táº¥t cáº£ khÃ´ng lá»c"""
        x1, y1, x2, y2 = result.xyxy[0].tolist()
        
        # Scale vá» tá»a Ä‘á»™ áº£nh gá»‘c
        scaled_x1 = int(x1 * scale_x)
        scaled_y1 = int(y1 * scale_y)
        scaled_x2 = int(x2 * scale_x)
        scaled_y2 = int(y2 * scale_y)
        
        # TÃ­nh kÃ­ch thÆ°á»›c
        width = scaled_x2 - scaled_x1
        height = scaled_y2 - scaled_y1
        area = width * height
        
        bbox_info = {
            "index": bbox_index,
            "class_id": int(result.cls[0]),
            "confidence": float(result.conf[0]),
            "bbox": [scaled_x1, scaled_y1, scaled_x2, scaled_y2],
            "width": width,
            "height": height,
            "area": area
        }
        
        # === Crop vÃ  lÆ°u Táº¤T Cáº¢ bbox ===
        cropped = fitz_img[scaled_y1:scaled_y2, scaled_x1:scaled_x2]
        
        # LÃ m nÃ©t áº£nh báº±ng kernel sharpen
        sharpen_kernel = np.array([[0, -1, 0],
                                   [-1, 5, -1],
                                   [0, -1, 0]])
        sharpened = cv2.filter2D(cropped, -1, sharpen_kernel)
        
        # LÆ°u vá»›i tÃªn file
        crop_filename = f"crop_{crop_count:03d}_cls{int(result.cls[0])}.png"
        crop_path = crop_subdir / crop_filename
        
        # Chuyá»ƒn tá»« RGB sang BGR trÆ°á»›c khi lÆ°u (vÃ¬ cv2.imwrite expect BGR)
        cv2.imwrite(str(crop_path), cv2.cvtColor(sharpened, cv2.COLOR_RGB2BGR))
        
        bbox_info["crop_path"] = str(crop_path)
        bbox_info["crop_filename"] = crop_filename
        
        print(f"      âœ… Bbox {bbox_index} -> crop_{crop_count}: [{scaled_x1}, {scaled_y1}, {scaled_x2}, {scaled_y2}] "
              f"(W:{width}, H:{height}, Area:{area:,}) -> {crop_filename}")
        
        return {
            "bbox_info": bbox_info
        }
    

    
    def _create_empty_result(self, image_path, image_name, fitz_w, fitz_h, yolo_w, yolo_h, scale_x, scale_y):
        """Táº¡o káº¿t quáº£ rá»—ng cho áº£nh khÃ´ng cÃ³ bbox"""
        return {
            "image_info": {
                "original_path": str(image_path),
                "image_name": image_name,
                "original_filename": image_path.name,
                "image_size": [fitz_w, fitz_h],
                "yolo_size": [yolo_w, yolo_h],
                "scale": [scale_x, scale_y]
            },
            "statistics": {
                "total_boxes": 0,
                "cropped_boxes": 0
            },
            "all_bboxes": [],
            "paths": {
                "all_detections": None,
                "annotated": None,
                "cropped_folder": None
            },
            "status": "no_detection"
        }
    
    def process_batch(self):
        """Xá»­ lÃ½ táº¥t cáº£ áº£nh trong thÆ° má»¥c"""
        # Load model
        if not self.load_model():
            return False
        
        # Láº¥y danh sÃ¡ch file áº£nh
        image_files = self.get_image_files()
        self.total_images = len(image_files)
        
        if self.total_images == 0:
            print("âŒ KhÃ´ng tÃ¬m tháº¥y file áº£nh nÃ o trong thÆ° má»¥c!")
            return False
        
        print(f"\nğŸš€ Báº¯t Ä‘áº§u xá»­ lÃ½ {self.total_images} áº£nh...")
        
        # Xá»­ lÃ½ tá»«ng áº£nh
        all_results = []
        
        for i, image_path in enumerate(image_files):
            result = self.process_single_image(image_path, i)
            all_results.append(result)
            
            if result["status"] == "success":
                self.processed_images += 1
        
        # === LÆ°u káº¿t quáº£ tá»•ng há»£p ===
        self._save_batch_results(all_results)
        
        # === Thá»‘ng kÃª cuá»‘i cÃ¹ng ===
        self._print_final_statistics()
        
        return True
    
    def _save_batch_results(self, all_results):
        """LÆ°u káº¿t quáº£ tá»•ng há»£p trong thÆ° má»¥c gá»‘c output"""
        batch_result = {
                            "config": {
                "input_directory": str(self.input_dir),
                "output_directory": str(self.output_dir),
                "all_detections_directory": str(self.all_detections_dir),
                # "valid_detections_directory": str(self.valid_detections_dir),
                "cropped_directory": str(self.cropped_dir),
                "filtering": "disabled - take all bboxes",
                "supported_formats": list(self.SUPPORTED_FORMATS),
                "processing_time": datetime.now().isoformat()
            },
            "batch_statistics": {
                "total_images": self.total_images,
                "processed_images": self.processed_images,
                "failed_images": self.failed_images,
                "success_rate": self.processed_images/self.total_images*100 if self.total_images > 0 else 0,
                "total_bboxes": self.total_bboxes,
                "total_cropped_bboxes": self.total_valid_bboxes,
                "crop_rate": 100.0  # 100% vÃ¬ khÃ´ng lá»c
            },
            "results": all_results
        }
        
        # LÆ°u JSON tá»•ng há»£p trong thÆ° má»¥c gá»‘c output
        # batch_json_path = self.output_dir / "batch_results.json"
        # with open(batch_json_path, "w", encoding='utf-8') as f:
        #     json.dump(batch_result, f, ensure_ascii=False, indent=2)
        
        # print(f"\nğŸ’¾ ÄÃ£ lÆ°u káº¿t quáº£ tá»•ng há»£p: {batch_json_path}")
    
    def _print_final_statistics(self):
        """In thá»‘ng kÃª cuá»‘i cÃ¹ng"""
        print(f"\n" + "="*60)
        print(f"ğŸ¯ HOÃ€N THÃ€NH Xá»¬ LÃ BATCH")
        print(f"="*60)
        print(f"ğŸ“Š Thá»‘ng kÃª tá»•ng quan:")
        print(f"   - Tá»•ng sá»‘ áº£nh: {self.total_images}")
        print(f"   - áº¢nh xá»­ lÃ½ thÃ nh cÃ´ng: {self.processed_images}")
        print(f"   - áº¢nh bá»‹ lá»—i: {self.failed_images}")
        print(f"   - Tá»· lá»‡ thÃ nh cÃ´ng: {self.processed_images/self.total_images*100:.1f}%")
        print(f"   - Tá»•ng bbox phÃ¡t hiá»‡n: {self.total_bboxes:,}")
        print(f"   - Tá»•ng bbox Ä‘Ã£ crop: {self.total_valid_bboxes:,}")
        print(f"   - Tá»· lá»‡ crop: 100% (khÃ´ng lá»c)")
        
        print(f"\nğŸ“ Káº¿t quáº£ Ä‘áº§u ra:")
        print(f"   - áº¢nh táº¥t cáº£ detections: {self.all_detections_dir}")
        # print(f"   - áº¢nh valid detections: {self.valid_detections_dir}")
        print(f"   - áº¢nh crop: {self.cropped_dir}")
        print(f"   - JSON tá»•ng há»£p: {self.output_dir}/batch_results.json")


def main():
    # === Cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n ===
    INPUT_DIR = "books_to_images/30-de-thi"  # Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n nÃ y
    OUTPUT_DIR = "."  # Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n nÃ y
    
    # Táº¡o processor vÃ  cháº¡y
    processor = YOLOBatchProcessor(INPUT_DIR, OUTPUT_DIR)
    processor.process_batch()


if __name__ == "__main__":
    main()